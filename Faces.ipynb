{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jap Idol challenge\n",
    "Try to correctly classify images depicting faces of 40 famous japanese idol. The dataset is composed of 7200 112x112  rgb image divided into 6 different tfrecords file. \n",
    "Unfortunatelly I have not been able to trace back the original author of the dataset, if you know him let me know and I'll had credits where are due."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)Input reading\n",
    "Craete symbolic ops to read single examples from train and validation set, then create minibatch with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def read_and_decode_tfrecords(filenames,image_shape):\n",
    "    \"\"\"\n",
    "    Read and decode tfrecords from the list of files filenames, returns a single image and label as tensorflow op\n",
    "    \"\"\"\n",
    "    \n",
    "    #create filename queue\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    \n",
    "    #symbolic reader to read one example at a time\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    #read the fields of the single example\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        # Defaults are not specified since both keys are required.\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([1], tf.int64),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #decode the image data\n",
    "    image = tf.image.decode_jpeg(features['image_raw'], channels=image_shape[-1])\n",
    "    image.set_shape(image_shape)\n",
    "    \n",
    "    #convert to float --> tensorflow works only on float!\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    #compress range between [-1,1]\n",
    "    image = tf.div(image,127.5)\n",
    "    image = tf.sub(image,1)\n",
    "    \n",
    "    return image,features['label']\n",
    "\n",
    "#Params\n",
    "IMAGE_SHAPE = [112,112,3]\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#get_filenames\n",
    "cwd = os.getcwd()+'/data/faces/'\n",
    "tf_records_filenames = [os.path.join(cwd,f) for f in os.listdir(cwd)]\n",
    "training_set = tf_records_filenames[:-1] #use 5 out of 6 tfrecord as training set\n",
    "validation_set = [tf_records_filenames[-1]]   #use 1 out of 6 tfrecord as validation set\n",
    "\n",
    "print('Going to train on: {}'.format(training_set))\n",
    "print('Going to validate on: {}'.format(validation_set))\n",
    "\n",
    "with tf.variable_scope('train_reader'):\n",
    "    #create single example op\n",
    "    image_t,label_t = read_and_decode_tfrecords(training_set,IMAGE_SHAPE)\n",
    "    #create minibatch \n",
    "    image_batch_t,label_batch_t = tf.train.shuffle_batch([image_t,label_t], batch_size=BATCH_SIZE, num_threads=8, capacity=1000, min_after_dequeue=300)\n",
    "    #create image summaries to diplay training image in tensorflow\n",
    "    tf.summary.image(\"train_images\",image_batch_t,max_outputs=5)\n",
    "    \n",
    "with tf.variable_scope('val_reader'):\n",
    "    image_v,label_v = read_and_decode_tfrecords(validation_set,IMAGE_SHAPE)\n",
    "    image_batch_v, label_batch_v = tf.train.shuffle_batch([image_v,label_v], batch_size=BATCH_SIZE, num_threads=8,capacity=1200, min_after_dequeue=600)\n",
    "    tf.summary.image(\"validation_image\",image_batch_v,max_outputs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)Model Definition\n",
    "Define a CNN model to predict one of the 40 possible classes, add summary op to visualize useful statistic in tensorboard.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Some utility function \n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    \"\"\"\n",
    "    Create image summaries and histogram for var.\n",
    "    \"\"\"\n",
    "    #summary operation must be run on cpu\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            mean = tf.reduce_mean(var)\n",
    "            tf.summary.scalar('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.summary.scalar('sttdev/' + name, stddev)\n",
    "        tf.summary.scalar('max/' + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/' + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n",
    "\n",
    "def conv(previous_layer, shape, stride):\n",
    "    kernel = tf.get_variable(\"kernel\", shape=shape,trainable=True, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    variable_summaries(kernel,\"kernel\")\n",
    "\n",
    "    bias = tf.get_variable(\"bias\", shape=[shape[-1]],trainable=True,initializer=tf.random_uniform_initializer(-0.5,0.5))\n",
    "    variable_summaries(bias,'bias')\n",
    "    \n",
    "    #conv +bias\n",
    "    conv = tf.nn.conv2d(previous_layer,kernel,stride,padding='SAME')\n",
    "    bias = tf.nn.bias_add(conv,bias)\n",
    "    return bias\n",
    "\n",
    "def fc(previous_layer, num_nodes):\n",
    "    input_num_features = previous_layer.get_shape()[-1]\n",
    "    weight_shape = [input_num_features,num_nodes]\n",
    "    \n",
    "    weights = tf.get_variable('weights',shape=weight_shape, trainable=True, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    variable_summaries(weights,'weights')\n",
    "    \n",
    "    bias = tf.get_variable('bias',shape=[num_nodes], trainable=True, initializer=tf.random_uniform_initializer(-0.5,0.5))\n",
    "    variable_summaries(bias,'bias')\n",
    "    \n",
    "    return (tf.matmul(previous_layer,weights)+bias)\n",
    "\n",
    "def getModel(image,num_classes):\n",
    "    net = image\n",
    "    input_channels = image.get_shape()[-1].value\n",
    "    \n",
    "    with tf.variable_scope('conv_1') as scope:\n",
    "        #32 5x5 convolutional filters + relu activation\n",
    "        net = conv(net,[5,5,input_channels,32],[1,1,1,1])\n",
    "        net = tf.nn.relu(net)\n",
    "    \n",
    "    with tf.variable_scope('pool1') as scope:\n",
    "        #max_pooling to halve dimensions\n",
    "        net = tf.nn.max_pool(net,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "   \n",
    "    with tf.variable_scope('conv_2') as scope:\n",
    "        #64 3x3 convolutional filters + relu activation\n",
    "        net = conv(net,[3,3,32,64],[1,1,1,1])\n",
    "        net = tf.nn.relu(net)\n",
    "    \n",
    "    with tf.variable_scope('pool_2') as scope:\n",
    "        #max pooling to halve dimensions\n",
    "        net = tf.nn.max_pool(net,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    with tf.variable_scope('conv_3') as scope:\n",
    "        #128 3x3 convolutional filters+relu\n",
    "        net = conv(net,[3,3,64,128],[1,1,1,1])\n",
    "        net=tf.nn.relu(net)\n",
    "    \n",
    "    with tf.variable_scope('pool_3') as scope:\n",
    "        #max pooling to halve dimensions\n",
    "        net = tf.nn.max_pool(net,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    with tf.variable_scope('conv_4') as scope:\n",
    "        #64 3x3 convolutional filters\n",
    "        net = conv(net,[3,3,128,64],[1,2,2,1])\n",
    "        net = tf.nn.relu(net)\n",
    "    \n",
    "    with tf.variable_scope('fc5') as scope:\n",
    "        #256 fully connected node + relu\n",
    "        linear_input_size = (net.get_shape()[-2].value**2) * net.get_shape()[-1].value\n",
    "        #linearize feature maps\n",
    "        net = tf.reshape(net,[BATCH_SIZE,linear_input_size])\n",
    "        \n",
    "        net = fc(net, 256)\n",
    "        net = tf.nn.relu(net)\n",
    "    \n",
    "    with tf.variable_scope('fc6') as scope:\n",
    "        #40 output fully connected node\n",
    "        net = fc(net,num_classes)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create two graph, one for training one for evaluation\n",
    "with tf.variable_scope('Network') as scope:\n",
    "    \n",
    "    #graph that takes as input the training batch\n",
    "    prediction_train = getModel(image_batch_t,40)\n",
    "    train_classification = tf.nn.softmax(prediction_train)\n",
    "    print('Train model ready')\n",
    "    \n",
    "    #enable sharing of variables between models\n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    #graph that takes as input the validation batch\n",
    "    prediction_val = getModel(image_batch_v,40)\n",
    "    validation_classification = tf.nn.softmax(prediction_val)\n",
    "    print('Validation model ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)Loss Function\n",
    "We are going to use once again cross entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss') as scope:\n",
    "    label_batch_t = tf.cast(label_batch_t, tf.int64)\n",
    "    label_batch_t = tf.reshape(label_batch_t,[BATCH_SIZE])\n",
    "\n",
    "    #our labels are not one hot encoded --> use sparse_softmax_cross_entropy\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label_batch_t, logits=prediction_train, name='cross_entropy')\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    #add summary op\n",
    "    tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)Optimizer\n",
    "Define a suitable optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)Accurcay Op\n",
    "Define an accuracy op to measure how well the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('accuracy') as scope:\n",
    "    label_batch_v = tf.cast(label_batch_v, tf.int64)\n",
    "    label_batch_v = tf.reshape(label_batch_v,[BATCH_SIZE])\n",
    "\n",
    "    correct_prediction = tf.equal(label_batch_v,tf.argmax(prediction_val,1))   #array of bool\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('validation_accuracy',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)Meta op\n",
    "Add utility op to save summaries and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init operation\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#summary operation for visualization\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "#create a saver to save and restore models\n",
    "saver = tf.train.Saver(tf.global_variables(),max_to_keep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_folder = 'log/faces'\n",
    "\n",
    "#create log folder if it does not exist\n",
    "if not os.path.exists(log_folder):\n",
    "    os.makedirs(log_folder)\n",
    "\n",
    "    \n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    max_step = 10000\n",
    "    step = 0\n",
    "    \n",
    "    #create summary writers\n",
    "    sum_writer = tf.summary.FileWriter(log_folder,sess.graph)\n",
    "    \n",
    "    #check if there is a weight checkpoint file in log_folder \n",
    "    ckpt = tf.train.get_checkpoint_state(log_folder)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        #if found restore saved model --> useful to split training in different moment of time\n",
    "        print('Founded valid checkpoint file at: '+ckpt.model_checkpoint_path)\n",
    "\n",
    "        #restore variable\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "        #restore step\n",
    "        step = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        print('Restored %d step model'%(step))\n",
    "    else:\n",
    "        #if no checkpoint file is found\n",
    "        print('No checkpoint file found, initialization instead')\n",
    "        \n",
    "        #init all variables\n",
    "        sess.run(init)\n",
    "\n",
    "    #start input threads \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    #start training procedure\n",
    "    for i in range(step,max_step):\n",
    "        #every step\n",
    "        start_time = time.time()\n",
    "        _,loss_value = sess.run([train_op,loss])\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if step%10 is 0:\n",
    "            #every 10 step evaluate on a validation batch and print info\n",
    "            validation_score = sess.run(accuracy)\n",
    "            \n",
    "            num_examples_per_step = BATCH_SIZE\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = float(duration)\n",
    "            \n",
    "            format_str = ('%s: step %d, loss = %.2f, validation_accuracy=%.2f,(%.1f examples/sec; %.3f sec/batch)')\n",
    "            print (format_str % (datetime.now(), step, loss_value,validation_score,examples_per_sec, sec_per_batch))\n",
    "        \n",
    "        if step%50 is 0:\n",
    "            #every 50 step save summaries\n",
    "            summary_str = sess.run(summary_op)\n",
    "            sum_writer.add_summary(summary_str, step)\n",
    "            \n",
    "        if step%1000 is 0:\n",
    "            #every 1000 step save checkpoint files with all the weights\n",
    "            checkpoint_path = os.path.join(log_folder, 'faces.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "            \n",
    "        step+=1\n",
    "    #shut down all the threads\n",
    "    coord.request_stop()\n",
    "\n",
    "print('ALL DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
